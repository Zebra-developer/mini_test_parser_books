import requests
from bs4 import BeautifulSoup
import csv

BASE_URL = "https://books.toscrape.com/catalogue/page-{}.html"
HEADERS = {
    "User-Agent": "Mozilla/5.0"
}

# –±–µ—Ä–µ–º –¥–∞–Ω–Ω—ã–µ –∫–Ω–∏–≥–∏ 
def get_books_from_page(page_number):
    url = BASE_URL.format(page_number)
    response = requests.get(url, headers=HEADERS)
    if response.status_code != 200:
        return []

    soup = BeautifulSoup(response.text, "html.parser")
    books = []

    for book in soup.select(".product_pod"):
        title = book.h3.a["title"]
        price = book.select_one(".price_color").text.strip()
        availability = book.select_one(".instock.availability").text.strip()
        books.append({
            "title": title,
            "price": price,
            "availability": availability
        })

    return books

# —Ñ—É–Ω–∫—Ü–∏—è —Å–∫—Ä–∞–ø–∏–Ω–∫–∞ –∫–Ω–∏–≥
def scrape_all_books(pages=5):
    all_books = []
    for page in range(1, pages + 1):
        print(f"üìÑ –°–∫–∞–Ω–∏—Ä—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É {page}...")
        books = get_books_from_page(page)
        all_books.extend(books)
    return all_books

# —Ñ—É–Ω–∫—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –∫–Ω–∏–≥ –≤ csv —Ñ–∞–π–ª
def save_to_csv(books, filename="books.csv"):
    with open(filename, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=["title", "price", "availability"])
        writer.writeheader()
        writer.writerows(books)
    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(books)} –∫–Ω–∏–≥ –≤ —Ñ–∞–π–ª {filename}")


if __name__ == "__main__":
    books_data = scrape_all_books(pages=10)  # –º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å –¥–æ 50
    save_to_csv(books_data)
